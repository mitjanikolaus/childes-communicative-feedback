{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lme4_1.1-27.1.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 3311365 bytes (3.2 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 3.2 MB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmprzJzSa/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Updating HTML index of packages in '.Library'\n",
      "\n",
      "R[write to console]: Making 'packages.html' ...\n",
      "R[write to console]:  done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "utils = importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('lme4')\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>transcript_raw</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>age</th>\n",
       "      <th>corpus</th>\n",
       "      <th>transcript_file</th>\n",
       "      <th>...</th>\n",
       "      <th>follow_up_transcript_raw</th>\n",
       "      <th>follow_up_start_time</th>\n",
       "      <th>follow_up_is_speech_related</th>\n",
       "      <th>follow_up_is_intelligible</th>\n",
       "      <th>follow_up_speech_act</th>\n",
       "      <th>response_latency</th>\n",
       "      <th>response_latency_follow_up</th>\n",
       "      <th>has_response</th>\n",
       "      <th>response_is_clarification_request</th>\n",
       "      <th>pos_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>CHI</td>\n",
       "      <td>let's get some glue too .</td>\n",
       "      <td>[\"let's\", 'get', 'some', 'glue', 'too', '.']</td>\n",
       "      <td>['v', 'pro:obj', 'v', 'qn', 'n', 'adv']</td>\n",
       "      <td>92795.0</td>\n",
       "      <td>96687.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>let's get some glue don't touch that .</td>\n",
       "      <td>97154.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>CHI</td>\n",
       "      <td>xxx I get some glue get some glue too .</td>\n",
       "      <td>['i', 'get', 'some', 'glue', 'too', '.']</td>\n",
       "      <td>['pro:sub', 'v', 'qn', 'n', 'adv']</td>\n",
       "      <td>141382.0</td>\n",
       "      <td>148262.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>xxx broken .</td>\n",
       "      <td>150114.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>CHI</td>\n",
       "      <td>xxx broken .</td>\n",
       "      <td>['broken', '.']</td>\n",
       "      <td>['part']</td>\n",
       "      <td>150114.0</td>\n",
       "      <td>151434.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>xxx table's leg .</td>\n",
       "      <td>155422.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>CHI</td>\n",
       "      <td>huh right there see his legs see table's legs .</td>\n",
       "      <td>['huh', 'right', 'there', 'see', 'his', 'legs'...</td>\n",
       "      <td>['co', 'adv', 'adv', 'v', 'det:poss', 'n', 'v'...</td>\n",
       "      <td>163402.0</td>\n",
       "      <td>169064.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>right .</td>\n",
       "      <td>172202.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3138.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>CHI</td>\n",
       "      <td>hi Jenny how you fine hi how you doing .</td>\n",
       "      <td>['hi', 'jenny', 'how', 'you', 'fine', 'hi', 'h...</td>\n",
       "      <td>['co', 'n:prop', 'pro:rel', 'pro:per', 'adv', ...</td>\n",
       "      <td>212706.0</td>\n",
       "      <td>243831.0</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>right .</td>\n",
       "      <td>249125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5294.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   utterance_id speaker_code                                   transcript_raw  \\\n",
       "0            28          CHI                        let's get some glue too .   \n",
       "1            50          CHI          xxx I get some glue get some glue too .   \n",
       "2            52          CHI                                     xxx broken .   \n",
       "3            58          CHI  huh right there see his legs see table's legs .   \n",
       "4            78          CHI         hi Jenny how you fine hi how you doing .   \n",
       "\n",
       "                                              tokens  \\\n",
       "0       [\"let's\", 'get', 'some', 'glue', 'too', '.']   \n",
       "1           ['i', 'get', 'some', 'glue', 'too', '.']   \n",
       "2                                    ['broken', '.']   \n",
       "3  ['huh', 'right', 'there', 'see', 'his', 'legs'...   \n",
       "4  ['hi', 'jenny', 'how', 'you', 'fine', 'hi', 'h...   \n",
       "\n",
       "                                                 pos  start_time  end_time  \\\n",
       "0            ['v', 'pro:obj', 'v', 'qn', 'n', 'adv']     92795.0   96687.0   \n",
       "1                 ['pro:sub', 'v', 'qn', 'n', 'adv']    141382.0  148262.0   \n",
       "2                                           ['part']    150114.0  151434.0   \n",
       "3  ['co', 'adv', 'adv', 'v', 'det:poss', 'n', 'v'...    163402.0  169064.0   \n",
       "4  ['co', 'n:prop', 'pro:rel', 'pro:per', 'adv', ...    212706.0  243831.0   \n",
       "\n",
       "   age corpus                                  transcript_file  ...  \\\n",
       "0   30  Bloom  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  ...   \n",
       "1   30  Bloom  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  ...   \n",
       "2   30  Bloom  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  ...   \n",
       "3   30  Bloom  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  ...   \n",
       "4   30  Bloom  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  ...   \n",
       "\n",
       "                 follow_up_transcript_raw follow_up_start_time  \\\n",
       "0  let's get some glue don't touch that .              97154.0   \n",
       "1                            xxx broken .             150114.0   \n",
       "2                       xxx table's leg .             155422.0   \n",
       "3                                 right .             172202.0   \n",
       "4                                 right .             249125.0   \n",
       "\n",
       "   follow_up_is_speech_related  follow_up_is_intelligible  \\\n",
       "0                            1                          1   \n",
       "1                            1                          1   \n",
       "2                            1                          1   \n",
       "3                            1                          1   \n",
       "4                            1                          1   \n",
       "\n",
       "   follow_up_speech_act  response_latency response_latency_follow_up  \\\n",
       "0                    PF               0.0                      467.0   \n",
       "1                    AA               0.0                     1852.0   \n",
       "2                    ST               0.0                     3988.0   \n",
       "3                    AD               0.0                     3138.0   \n",
       "4                    AA               0.0                     5294.0   \n",
       "\n",
       "  has_response  response_is_clarification_request  pos_feedback  \n",
       "0            1                                  0             1  \n",
       "1            1                                  0             1  \n",
       "2            1                                  0             1  \n",
       "3            1                                  0             1  \n",
       "4            1                                  0             1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "conversations = pd.read_csv(\"results/intelligibility/conversations.csv\")\n",
    "conversations_melted = pd.read_csv(\"results/intelligibility/conversations_melted.csv\")\n",
    "\n",
    "# convert True/False to 0/1:\n",
    "conversations.replace({False: 0, True: 1}, inplace=True)\n",
    "conversations_melted.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "conversations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corpus\n",
       "Bloom                   1042\n",
       "Braunwald               1948\n",
       "Brent                   2076\n",
       "Forrester                205\n",
       "Gleason                 6628\n",
       "MPI-EVA-Manchester    139924\n",
       "MacWhinney              9672\n",
       "NewmanRatner             140\n",
       "Peters                  5363\n",
       "Providence             46594\n",
       "Rollins                  113\n",
       "Sachs                   2596\n",
       "Snow                    6105\n",
       "Soderstrom              1404\n",
       "Thomas                111165\n",
       "Tommerdahl              5287\n",
       "Weist                   8395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some children have very few data points:\n",
    "counts = conversations.groupby(\"corpus\").size()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize age\n",
    "min_age, max_age = conversations[\"age\"].min(), conversations[\"age\"].max()\n",
    "conversations[\"age\"] = (conversations[\"age\"] - min_age) / (max_age - min_age) * (1 - 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of communicative feedback/ Caregiver contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: has_response ~ is_intelligible * age + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "180541.4 180592.1 -90265.7 180531.4   187471 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-8.6210  0.1439  0.4934  0.5347  0.9662 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 1.356    1.165   \n",
      "Number of obs: 187476, groups:  child_name, 31\n",
      "\n",
      "Fixed effects:\n",
      "                    Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)          1.78962    0.15349  11.660   <2e-16 ***\n",
      "is_intelligible      0.99341    0.04343  22.874   <2e-16 ***\n",
      "age                  1.15514    0.08013  14.416   <2e-16 ***\n",
      "is_intelligible:age -0.13875    0.08246  -1.683   0.0924 .  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl age   \n",
      "is_intllgbl -0.050              \n",
      "age         -0.054  0.766       \n",
      "is_ntllgbl:  0.049 -0.912 -0.854\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('has_response ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: response_is_clarification_request ~ is_intelligible * age + (1 |  \n",
      "    child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      " 15664.5  15715.2  -7827.2  15654.5   187798 \n",
      "\n",
      "Scaled residuals: \n",
      "   Min     1Q Median     3Q    Max \n",
      "-0.358 -0.073 -0.070 -0.068 37.636 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 1.228    1.108   \n",
      "Number of obs: 187803, groups:  child_name, 39\n",
      "\n",
      "Fixed effects:\n",
      "                    Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)          -2.9402     0.2498 -11.770  < 2e-16 ***\n",
      "is_intelligible      -2.4388     0.1314 -18.567  < 2e-16 ***\n",
      "age                  -1.4524     0.2158  -6.730 1.70e-11 ***\n",
      "is_intelligible:age   1.0451     0.2356   4.436 9.14e-06 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl age   \n",
      "is_intllgbl -0.201              \n",
      "age         -0.318  0.496       \n",
      "is_ntllgbl:  0.198 -0.897 -0.621\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "# TODO: filter out no response cases?\n",
    "m_caregiver_contingency<-glmer('response_is_clarification_request ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (Positive Feedback = No pause, no clarification request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: pos_feedback ~ is_intelligible * age + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "184200.0 184250.8 -92095.0 184190.0   187829 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-7.2747  0.1601  0.4997  0.5418  1.0355 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 0.8515   0.9228  \n",
      "Number of obs: 187834, groups:  child_name, 40\n",
      "\n",
      "Fixed effects:\n",
      "                    Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)          1.33834    0.14175   9.441   <2e-16 ***\n",
      "is_intelligible      1.12552    0.04114  27.360   <2e-16 ***\n",
      "age                  1.21939    0.07799  15.636   <2e-16 ***\n",
      "is_intelligible:age -0.19354    0.07821  -2.475   0.0133 *  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl age   \n",
      "is_intllgbl -0.128              \n",
      "age         -0.144  0.746       \n",
      "is_ntllgbl:  0.122 -0.903 -0.843\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('pos_feedback ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of communicative feedback\n",
    "### Positive Feedback: Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: follow_up_is_intelligible ~ has_response * age + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "105692.5 105743.2 -52841.2 105682.5   187829 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-8.6859  0.2320  0.2554  0.3281  3.7015 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 2.91     1.706   \n",
      "Number of obs: 187834, groups:  child_name, 40\n",
      "\n",
      "Fixed effects:\n",
      "                 Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)       1.64205    0.15479  10.608  < 2e-16 ***\n",
      "has_response      1.13774    0.04273  26.628  < 2e-16 ***\n",
      "age               1.74680    0.07592  23.008  < 2e-16 ***\n",
      "has_response:age -0.53273    0.08113  -6.567 5.15e-11 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) hs_rsp age   \n",
      "has_respons -0.097              \n",
      "age         -0.116  0.538       \n",
      "has_rspns:g  0.098 -0.909 -0.626\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "# conversations_child_intelligible = subset(conversations, is_intelligible==1)\n",
    "# TODO: only intelligible ones?\n",
    "\n",
    "m_child_contingency<-glmer('follow_up_is_intelligible ~ has_response * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Negative Feedback: Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: is_intelligible ~ is_follow_up + age + (1 | child_name) + (1 |  \n",
      "    is_follow_up)\n",
      "   Data: conversations_melted_cr\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "  4056.3   4087.4  -2023.1   4046.3     3735 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-5.8983 -0.8930  0.4035  0.6665  2.5446 \n",
      "\n",
      "Random effects:\n",
      " Groups       Name        Variance Std.Dev.\n",
      " child_name   (Intercept) 1.059    1.029   \n",
      " is_follow_up (Intercept) 0.000    0.000   \n",
      "Number of obs: 3740, groups:  child_name, 47; is_follow_up, 2\n",
      "\n",
      "Fixed effects:\n",
      "              Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)  -2.167157   0.287775  -7.531 5.05e-14 ***\n",
      "is_follow_up  0.836519   0.078459  10.662  < 2e-16 ***\n",
      "age           0.086483   0.006925  12.489  < 2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_fl_\n",
      "is_follow_p -0.173       \n",
      "age         -0.741  0.075\n",
      "optimizer (Nelder_Mead) convergence code: 0 (OK)\n",
      "boundary (singular) fit: see ?isSingular\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations_melted\n",
    "library(lme4)\n",
    "\n",
    "conversations_melted_cr = subset(conversations_melted, response_is_clarification_request == 1)\n",
    "\n",
    "\n",
    "m_child_contingency<-glmer('is_intelligible ~ is_follow_up + age + (1 | child_name) + (1 | is_follow_up)', data=conversations_melted_cr, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: is_intelligible ~ response_is_clarification_request * is_follow_up +  \n",
      "    (1 | age) + (1 | child_name) + (1 | is_follow_up)\n",
      "   Data: conversations_melted\n",
      "\n",
      "      AIC       BIC    logLik  deviance  df.resid \n",
      " 382871.7  382951.9 -191428.9  382857.7    696897 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-8.2339  0.2274  0.2477  0.3078 12.4579 \n",
      "\n",
      "Random effects:\n",
      " Groups       Name        Variance Std.Dev.\n",
      " child_name   (Intercept) 2.786    1.669   \n",
      " age          (Intercept) 1.418    1.191   \n",
      " is_follow_up (Intercept) 0.000    0.000   \n",
      "Number of obs: 696904, groups:  child_name, 51; age, 8; is_follow_up, 2\n",
      "\n",
      "Fixed effects:\n",
      "                                                Estimate Std. Error z value\n",
      "(Intercept)                                     1.393185   0.070020  19.897\n",
      "response_is_clarification_request              -1.908779   0.037073 -51.487\n",
      "is_follow_up                                   -0.060192   0.008654  -6.955\n",
      "response_is_clarification_request:is_follow_up  0.894052   0.051724  17.285\n",
      "                                               Pr(>|z|)    \n",
      "(Intercept)                                     < 2e-16 ***\n",
      "response_is_clarification_request               < 2e-16 ***\n",
      "is_follow_up                                   3.52e-12 ***\n",
      "response_is_clarification_request:is_follow_up  < 2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) rsp___ is_fl_\n",
      "rspns_s_cl_  0.020              \n",
      "is_follow_p -0.011  0.035       \n",
      "rspns___:__  0.073 -0.437 -0.076\n",
      "optimizer (Nelder_Mead) convergence code: 0 (OK)\n",
      "boundary (singular) fit: see ?isSingular\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations_melted\n",
    "library(lme4)\n",
    "\n",
    "m_child_contingency<-glmer('is_intelligible ~ response_is_clarification_request * is_follow_up + (1 | age) + (1 | child_name) + (1 | is_follow_up)', data=conversations_melted, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}