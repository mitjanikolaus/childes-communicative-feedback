{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lme4_1.1-27.1.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 3311365 bytes (3.2 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 3.2 MB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmprzJzSa/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Updating HTML index of packages in '.Library'\n",
      "\n",
      "R[write to console]: Making 'packages.html' ...\n",
      "R[write to console]:  done\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "utils = importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('lme4')\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>age</th>\n",
       "      <th>corpus</th>\n",
       "      <th>transcript_file</th>\n",
       "      <th>child_name</th>\n",
       "      <th>speaker_code_next</th>\n",
       "      <th>start_time_next</th>\n",
       "      <th>...</th>\n",
       "      <th>follow_up_start_time</th>\n",
       "      <th>follow_up_end_time</th>\n",
       "      <th>follow_up_is_speech_related</th>\n",
       "      <th>follow_up_is_intelligible</th>\n",
       "      <th>follow_up_speech_act</th>\n",
       "      <th>response_latency</th>\n",
       "      <th>response_latency_follow_up</th>\n",
       "      <th>has_response</th>\n",
       "      <th>response_is_clarification_request</th>\n",
       "      <th>pos_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>CHI</td>\n",
       "      <td>[\"let's\", 'get', 'some', 'glue', 'too', '.']</td>\n",
       "      <td>['v', 'pro:obj', 'v', 'qn', 'n', 'adv']</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>Bloom_Peter</td>\n",
       "      <td>MOT</td>\n",
       "      <td>96687.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97154.0</td>\n",
       "      <td>100026.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>CHI</td>\n",
       "      <td>['i', 'get', 'some', 'glue', 'too', '.']</td>\n",
       "      <td>['pro:sub', 'v', 'qn', 'n', 'adv']</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>Bloom_Peter</td>\n",
       "      <td>MOT</td>\n",
       "      <td>148262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>150114.0</td>\n",
       "      <td>151434.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>CHI</td>\n",
       "      <td>['broken', '.']</td>\n",
       "      <td>['part']</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>Bloom_Peter</td>\n",
       "      <td>MOT</td>\n",
       "      <td>151434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155422.0</td>\n",
       "      <td>161449.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3988.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>CHI</td>\n",
       "      <td>['huh', 'right', 'there', 'see', 'his', 'legs'...</td>\n",
       "      <td>['co', 'adv', 'adv', 'v', 'det:poss', 'n', 'v'...</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>Bloom_Peter</td>\n",
       "      <td>MOT</td>\n",
       "      <td>169064.0</td>\n",
       "      <td>...</td>\n",
       "      <td>172202.0</td>\n",
       "      <td>173521.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3138.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>CHI</td>\n",
       "      <td>['hi', 'jenny', 'how', 'you', 'fine', 'hi', 'h...</td>\n",
       "      <td>['co', 'n:prop', 'pro:rel', 'pro:per', 'adv', ...</td>\n",
       "      <td>30</td>\n",
       "      <td>Bloom</td>\n",
       "      <td>/home/mitja/data/CHILDES/Bloom/Peter/020324.cha</td>\n",
       "      <td>Bloom_Peter</td>\n",
       "      <td>MOT</td>\n",
       "      <td>243831.0</td>\n",
       "      <td>...</td>\n",
       "      <td>249125.0</td>\n",
       "      <td>249641.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5294.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   utterance_id speaker_code  \\\n",
       "0            28          CHI   \n",
       "1            50          CHI   \n",
       "2            52          CHI   \n",
       "3            58          CHI   \n",
       "4            78          CHI   \n",
       "\n",
       "                                              tokens  \\\n",
       "0       [\"let's\", 'get', 'some', 'glue', 'too', '.']   \n",
       "1           ['i', 'get', 'some', 'glue', 'too', '.']   \n",
       "2                                    ['broken', '.']   \n",
       "3  ['huh', 'right', 'there', 'see', 'his', 'legs'...   \n",
       "4  ['hi', 'jenny', 'how', 'you', 'fine', 'hi', 'h...   \n",
       "\n",
       "                                                 pos  age corpus  \\\n",
       "0            ['v', 'pro:obj', 'v', 'qn', 'n', 'adv']   30  Bloom   \n",
       "1                 ['pro:sub', 'v', 'qn', 'n', 'adv']   30  Bloom   \n",
       "2                                           ['part']   30  Bloom   \n",
       "3  ['co', 'adv', 'adv', 'v', 'det:poss', 'n', 'v'...   30  Bloom   \n",
       "4  ['co', 'n:prop', 'pro:rel', 'pro:per', 'adv', ...   30  Bloom   \n",
       "\n",
       "                                   transcript_file   child_name  \\\n",
       "0  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  Bloom_Peter   \n",
       "1  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  Bloom_Peter   \n",
       "2  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  Bloom_Peter   \n",
       "3  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  Bloom_Peter   \n",
       "4  /home/mitja/data/CHILDES/Bloom/Peter/020324.cha  Bloom_Peter   \n",
       "\n",
       "  speaker_code_next  start_time_next  ...  follow_up_start_time  \\\n",
       "0               MOT          96687.0  ...               97154.0   \n",
       "1               MOT         148262.0  ...              150114.0   \n",
       "2               MOT         151434.0  ...              155422.0   \n",
       "3               MOT         169064.0  ...              172202.0   \n",
       "4               MOT         243831.0  ...              249125.0   \n",
       "\n",
       "  follow_up_end_time  follow_up_is_speech_related  follow_up_is_intelligible  \\\n",
       "0           100026.0                            1                          1   \n",
       "1           151434.0                            1                          1   \n",
       "2           161449.0                            1                          1   \n",
       "3           173521.0                            1                          1   \n",
       "4           249641.0                            1                          1   \n",
       "\n",
       "   follow_up_speech_act  response_latency response_latency_follow_up  \\\n",
       "0                    PF               0.0                      467.0   \n",
       "1                    AA               0.0                     1852.0   \n",
       "2                    ST               0.0                     3988.0   \n",
       "3                    AD               0.0                     3138.0   \n",
       "4                    AA               0.0                     5294.0   \n",
       "\n",
       "  has_response  response_is_clarification_request  pos_feedback  \n",
       "0            1                                  0             1  \n",
       "1            1                                  0             1  \n",
       "2            1                                  0             1  \n",
       "3            1                                  0             1  \n",
       "4            1                                  0             1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "conversations = pd.read_csv(\"results/intelligibility/conversations.csv\")\n",
    "conversations_melted = pd.read_csv(\"results/intelligibility/conversations_melted.csv\")\n",
    "\n",
    "# convert True/False to 0/1:\n",
    "conversations.replace({False: 0, True: 1}, inplace=True)\n",
    "conversations_melted.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "conversations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "corpus\n",
       "Bloom                   1042\n",
       "Braunwald               1948\n",
       "Brent                   2076\n",
       "Forrester                205\n",
       "Gleason                 6628\n",
       "MPI-EVA-Manchester    139924\n",
       "MacWhinney              9672\n",
       "NewmanRatner             140\n",
       "Peters                  5363\n",
       "Providence             46594\n",
       "Rollins                  113\n",
       "Sachs                   2596\n",
       "Snow                    6105\n",
       "Soderstrom              1404\n",
       "Thomas                111165\n",
       "Tommerdahl              5287\n",
       "Weist                   8395\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some children have very few data points:\n",
    "counts = conversations.groupby(\"corpus\").size()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize age\n",
    "min_age, max_age = conversations[\"age\"].min(), conversations[\"age\"].max()\n",
    "conversations[\"age\"] = (conversations[\"age\"] - min_age) / (max_age - min_age) * (1 - 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of communicative feedback/ Caregiver contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: has_response ~ utt_is_intelligible * age + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "      AIC       BIC    logLik  deviance  df.resid \n",
      " 292958.1  293012.0 -146474.1  292948.1    348652 \n",
      "\n",
      "Scaled residuals: \n",
      "     Min       1Q   Median       3Q      Max \n",
      "-24.3846   0.0935   0.4958   0.5367   3.9572 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 3.596    1.896   \n",
      "Number of obs: 348657, groups:  child_name, 52\n",
      "\n",
      "Fixed effects:\n",
      "                        Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)              2.33381    0.14693  15.884   <2e-16 ***\n",
      "utt_is_intelligible      0.81883    0.04350  18.822   <2e-16 ***\n",
      "age                      0.95097    0.07368  12.906   <2e-16 ***\n",
      "utt_is_intelligible:age  0.05398    0.07930   0.681    0.496    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) utt_s_ age   \n",
      "utt_s_ntllg  0.103              \n",
      "age          0.120  0.845       \n",
      "utt_s_ntll: -0.117 -0.939 -0.912\n",
      "optimizer (Nelder_Mead) convergence code: 0 (OK)\n",
      "Model failed to converge with max|grad| = 0.00297025 (tol = 0.002, component 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('has_response ~ utt_is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "# TODO: filter out no response cases?\n",
    "m_caregiver_contingency<-glmer('response_is_clarification_request ~ utt_is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (Positive Feedback = No pause, no clarification request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('pos_feedback ~ utt_is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of communicative feedback\n",
    "### Positive Feedback: Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "# conversations_child_intelligible = subset(conversations, is_intelligible==1)\n",
    "# TODO: only intelligible ones?\n",
    "\n",
    "m_child_contingency<-glmer('follow_up_is_intelligible ~ has_response * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Negative Feedback: Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i conversations_melted\n",
    "library(lme4)\n",
    "\n",
    "conversations_melted_cr = subset(conversations_melted, response_is_clarification_request == 1)\n",
    "\n",
    "\n",
    "m_child_contingency<-glmer('is_intelligible ~ is_follow_up + (1 | age) + (1 | child_name) + (1 | is_follow_up)', data=conversations_melted_cr, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i conversations_melted\n",
    "library(lme4)\n",
    "\n",
    "m_child_contingency<-glmer('is_intelligible ~ response_is_clarification_request * is_follow_up + (1 | age) + (1 | child_name) + (1 | is_follow_up)', data=conversations_melted, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}