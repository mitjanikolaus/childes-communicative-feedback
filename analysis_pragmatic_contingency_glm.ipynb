{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lme4_1.1-27.1.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 3311365 bytes (3.2 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 3.2 MB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpPaPetR/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Updating HTML index of packages in '.Library'\n",
      "\n",
      "R[write to console]: Making 'packages.html' ...\n",
      "R[write to console]:  done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "utils = importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('lme4')\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>transcript_raw</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>age</th>\n",
       "      <th>corpus</th>\n",
       "      <th>transcript_file</th>\n",
       "      <th>...</th>\n",
       "      <th>follow_up_start_time</th>\n",
       "      <th>follow_up_is_speech_related</th>\n",
       "      <th>follow_up_is_intelligible</th>\n",
       "      <th>follow_up_is_contingent</th>\n",
       "      <th>follow_up_speech_act</th>\n",
       "      <th>response_latency</th>\n",
       "      <th>response_latency_follow_up</th>\n",
       "      <th>has_response</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>response_is_clarification_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>15320.0</td>\n",
       "      <td>16139.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>19069.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>-252.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>367633.0</td>\n",
       "      <td>368084.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>370041.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>528.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>372007.0</td>\n",
       "      <td>372211.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>381680.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>6830.0</td>\n",
       "      <td>9469.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>381680.0</td>\n",
       "      <td>381906.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>386103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>4197.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=babble .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>512973.0</td>\n",
       "      <td>513639.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>517483.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>361.0</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   utterance_id speaker_code transcript_raw tokens       pos  start_time  \\\n",
       "0             9          CHI   &=vocalize .  ['.']  ['none']     15320.0   \n",
       "1           157          CHI   &=vocalize .  ['.']  ['none']    367633.0   \n",
       "2           160          CHI   &=vocalize .  ['.']  ['none']    372007.0   \n",
       "3           162          CHI   &=vocalize .  ['.']  ['none']    381680.0   \n",
       "4           194          CHI     &=babble .  ['.']  ['none']    512973.0   \n",
       "\n",
       "   end_time  age corpus                               transcript_file  ...  \\\n",
       "0   16139.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "1  368084.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "2  372211.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "3  381906.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "4  513639.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "\n",
       "  follow_up_start_time follow_up_is_speech_related  follow_up_is_intelligible  \\\n",
       "0              19069.0                         1.0                          0   \n",
       "1             370041.0                         1.0                          0   \n",
       "2             381680.0                         1.0                          0   \n",
       "3             386103.0                         1.0                          0   \n",
       "4             517483.0                         1.0                          0   \n",
       "\n",
       "   follow_up_is_contingent  follow_up_speech_act  response_latency  \\\n",
       "0                        0                    YY            -252.0   \n",
       "1                        0                    YY             528.0   \n",
       "2                        0                    YY            6830.0   \n",
       "3                        0                    YY            1965.0   \n",
       "4                        0                    YY             361.0   \n",
       "\n",
       "  response_latency_follow_up has_response  pos_feedback  \\\n",
       "0                     2930.0            1             1   \n",
       "1                     1957.0            1             1   \n",
       "2                     9469.0            0             0   \n",
       "3                     4197.0            0             0   \n",
       "4                     3844.0            1             1   \n",
       "\n",
       "  response_is_clarification_request  \n",
       "0                                 0  \n",
       "1                                 0  \n",
       "2                                 0  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "conversations = pd.read_csv(\"results/contingency/conversations.csv\")\n",
    "conversations_melted = pd.read_csv(\"results/contingency/conversations_melted.csv\")\n",
    "\n",
    "# convert True/False to 0/1:\n",
    "conversations.replace({False: 0, True: 1}, inplace=True)\n",
    "conversations_melted.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "conversations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "child_name\n",
       "Braunwald_Laura                7529\n",
       "Brent_Alexander                 133\n",
       "Brent_Allen                       3\n",
       "Brent_Brooklyn                    8\n",
       "Brent_Dillon                    532\n",
       "Brent_Henry                      92\n",
       "Brent_Jacob_Abernathy             4\n",
       "Brent_Jaylen                     35\n",
       "Brent_Maggie                    114\n",
       "Brent_Miranda                   105\n",
       "Brent_Morgan                    414\n",
       "Brent_Tabitha                   187\n",
       "Brent_Tabitha_Sims                3\n",
       "Brent_Timothy                   306\n",
       "Brent_Tyrese                      6\n",
       "Brent_Vas                        11\n",
       "Brent_Vas_Coleman                87\n",
       "Brent_Xavier                      9\n",
       "MPI-EVA-Manchester_Eleanor    40925\n",
       "MPI-EVA-Manchester_Fraser     90496\n",
       "Thomas_Brian                    302\n",
       "Thomas_Thomas                 90240\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some children have very few data points:\n",
    "counts = conversations.groupby(\"child_name\").size()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Exclude children with less than 100 datapoints:\n",
    "# child_names_enough_data = [name for name, count in counts.items() if count > 100]\n",
    "# print(len(conversations))\n",
    "# conversations = conversations[conversations.child_name.isin(child_names_enough_data)]\n",
    "# print(len(conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize age\n",
    "min_age, max_age = conversations[\"age\"].min(), conversations[\"age\"].max()\n",
    "conversations[\"age\"] = (conversations[\"age\"] - min_age) / (max_age - min_age) * (1 - 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of communicative feedback/ Caregiver contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: has_response ~ is_intelligible * age_normalized + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "173345.9 173397.7 -86668.0 173335.9   231536 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-4.4872  0.3109  0.3410  0.3895  0.9238 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 0.2714   0.5209  \n",
      "Number of obs: 231541, groups:  child_name, 22\n",
      "\n",
      "Fixed effects:\n",
      "                               Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                     0.78918    0.10351   7.624 2.46e-14 ***\n",
      "is_intelligible                 0.79457    0.04085  19.449  < 2e-16 ***\n",
      "age_normalized                  0.66146    0.06743   9.810  < 2e-16 ***\n",
      "is_intelligible:age_normalized  0.44585    0.07488   5.954 2.62e-09 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl ag_nrm\n",
      "is_intllgbl -0.048              \n",
      "age_normlzd -0.047  0.724       \n",
      "is_ntllgb:_  0.038 -0.922 -0.802\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('has_response ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: \n",
      "response_is_clarification_request ~ is_intelligible * age_normalized +  \n",
      "    (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      " 15518.4  15570.2  -7754.2  15508.4   231536 \n",
      "\n",
      "Scaled residuals: \n",
      "   Min     1Q Median     3Q    Max \n",
      "-0.283 -0.075 -0.072 -0.031 36.393 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 1.056    1.028   \n",
      "Number of obs: 231541, groups:  child_name, 22\n",
      "\n",
      "Fixed effects:\n",
      "                               Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                     -3.7426     0.2366 -15.819  < 2e-16 ***\n",
      "is_intelligible                 -2.6123     0.1223 -21.367  < 2e-16 ***\n",
      "age_normalized                  -2.0319     0.2035  -9.987  < 2e-16 ***\n",
      "is_intelligible:age_normalized   1.6127     0.2326   6.934 4.09e-12 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl ag_nrm\n",
      "is_intllgbl  0.020              \n",
      "age_normlzd -0.090  0.412       \n",
      "is_ntllgb:_ -0.014 -0.893 -0.546\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('response_is_clarification_request ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (Positive Feedback = No pause, no clarification request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: pos_feedback ~ is_intelligible * age_normalized + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "177320.8 177372.6 -88655.4 177310.8   231536 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-4.2027  0.3113  0.3407  0.4003  0.9944 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 0.3022   0.5497  \n",
      "Number of obs: 231541, groups:  child_name, 22\n",
      "\n",
      "Fixed effects:\n",
      "                               Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                     0.62859    0.09246   6.798 1.06e-11 ***\n",
      "is_intelligible                 1.00836    0.04093  24.636  < 2e-16 ***\n",
      "age_normalized                  0.89248    0.06463  13.809  < 2e-16 ***\n",
      "is_intelligible:age_normalized  0.19024    0.07467   2.548   0.0108 *  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl ag_nrm\n",
      "is_intllgbl -0.065              \n",
      "age_normlzd -0.077  0.724       \n",
      "is_ntllgb:_  0.062 -0.925 -0.800\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('pos_feedback ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of communicative feedback\n",
    "### Positive Feedback: Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: follow_up_is_intelligible ~ has_response * age + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "166244.5 166296.4 -83117.2 166234.5   239545 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-4.4479  0.2742  0.3008  0.3758  9.0901 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 8.695    2.949   \n",
      "Number of obs: 239550, groups:  child_name, 21\n",
      "\n",
      "Fixed effects:\n",
      "                  Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)      -0.640520   0.199545  -3.210  0.00133 ** \n",
      "has_response      1.447956   0.069708  20.772  < 2e-16 ***\n",
      "age               0.052748   0.001926  27.388  < 2e-16 ***\n",
      "has_response:age -0.021891   0.002254  -9.713  < 2e-16 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) hs_rsp age   \n",
      "has_respons  0.051              \n",
      "age          0.034  0.756       \n",
      "has_rspns:g -0.050 -0.981 -0.781\n",
      "optimizer (Nelder_Mead) convergence code: 0 (OK)\n",
      "Model failed to converge with max|grad| = 0.0188126 (tol = 0.002, component 1)\n",
      "Model is nearly unidentifiable: very large eigenvalue\n",
      " - Rescale variables?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "# conversations_child_intelligible = subset(conversations, is_intelligible==1)\n",
    "# TODO: only intelligible ones?\n",
    "\n",
    "m_child_contingency<-glmer('follow_up_is_intelligible ~ has_response * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Negative Feedback: Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: is_intelligible ~ is_follow_up * age + (1 | child_name)\n",
      "   Data: conversations_melted_cr\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "  3131.5   3160.7  -1560.7   3121.5     2569 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-3.3500 -0.8805  0.5180  0.7752  1.8639 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 3.661    1.913   \n",
      "Number of obs: 2574, groups:  child_name, 12\n",
      "\n",
      "Fixed effects:\n",
      "                  Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)      -4.042170   1.009246  -4.005 6.20e-05 ***\n",
      "is_follow_up      0.999549   0.462461   2.161   0.0307 *  \n",
      "age               0.080437   0.010743   7.488 7.02e-14 ***\n",
      "is_follow_up:age -0.005366   0.015719  -0.341   0.7328    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_fl_ age   \n",
      "is_follow_p -0.286              \n",
      "age         -0.230  0.629       \n",
      "is_fllw_p:g  0.278 -0.982 -0.631\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations_melted\n",
    "library(lme4)\n",
    "\n",
    "conversations_melted_cr = subset(conversations_melted, response_is_clarification_request == 1)\n",
    "\n",
    "\n",
    "m_child_contingency<-glmer('is_intelligible ~ is_follow_up * age + (1 | child_name) + (1 | is_follow_up)', data=conversations_melted_cr, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see ?isSingular\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: is_intelligible ~ response_is_clarification_request * trial +  \n",
      "    (1 | child_name) + (1 | trial)\n",
      "   Data: data_new\n",
      "\n",
      "      AIC       BIC    logLik  deviance  df.resid \n",
      " 337864.3  337930.8 -168926.1  337852.3    479094 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-7.1152  0.3116  0.3541  0.3612  7.2539 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 8.11     2.848   \n",
      " trial      (Intercept) 0.00     0.000   \n",
      "Number of obs: 479100, groups:  child_name, 21; trial, 2\n",
      "\n",
      "Fixed effects:\n",
      "                                        Estimate Std. Error z value Pr(>|z|)\n",
      "(Intercept)                              0.81832    0.04948  16.539  < 2e-16\n",
      "response_is_clarification_request       -1.81910    0.04132 -44.024  < 2e-16\n",
      "trial                                   -0.03997    0.00895  -4.466 7.97e-06\n",
      "response_is_clarification_request:trial  0.84940    0.06480  13.108  < 2e-16\n",
      "                                           \n",
      "(Intercept)                             ***\n",
      "response_is_clarification_request       ***\n",
      "trial                                   ***\n",
      "response_is_clarification_request:trial ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) rsp___ trial \n",
      "rspns_s_cl_  0.027              \n",
      "trial        0.024  0.015       \n",
      "rspns_s_c_: -0.071 -0.569 -0.045\n",
      "optimizer (Nelder_Mead) convergence code: 0 (OK)\n",
      "boundary (singular) fit: see ?isSingular\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i data_new\n",
    "library(lme4)\n",
    "\n",
    "m_child_contingency<-glmer('is_intelligible ~ response_is_clarification_request * trial + (1 | child_name) + (1 | trial)', data=data_new, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}