{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: trying URL 'https://cloud.r-project.org/src/contrib/lme4_1.1-27.1.tar.gz'\n",
      "\n",
      "R[write to console]: Content type 'application/x-gzip'\n",
      "R[write to console]:  length 3311365 bytes (3.2 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 3.2 MB\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: \n",
      "R[write to console]: The downloaded source packages are in\n",
      "\t‘/tmp/RtmpEiuk1r/downloaded_packages’\n",
      "R[write to console]: \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: Updating HTML index of packages in '.Library'\n",
      "\n",
      "R[write to console]: Making 'packages.html' ...\n",
      "R[write to console]:  done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "utils = importr(\"utils\")\n",
    "utils.chooseCRANmirror(ind=1)\n",
    "utils.install_packages('lme4')\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance_id</th>\n",
       "      <th>speaker_code</th>\n",
       "      <th>transcript_raw</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>age</th>\n",
       "      <th>corpus</th>\n",
       "      <th>transcript_file</th>\n",
       "      <th>...</th>\n",
       "      <th>follow_up_start_time</th>\n",
       "      <th>follow_up_is_speech_related</th>\n",
       "      <th>follow_up_is_intelligible</th>\n",
       "      <th>follow_up_is_contingent</th>\n",
       "      <th>follow_up_speech_act</th>\n",
       "      <th>response_latency</th>\n",
       "      <th>response_latency_follow_up</th>\n",
       "      <th>has_response</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>response_is_clarification_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>15320.0</td>\n",
       "      <td>16139.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>19069.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>-252.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>367633.0</td>\n",
       "      <td>368084.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>370041.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>528.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>372007.0</td>\n",
       "      <td>372211.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>381680.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>6830.0</td>\n",
       "      <td>9469.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=vocalize .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>381680.0</td>\n",
       "      <td>381906.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>386103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>4197.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194</td>\n",
       "      <td>CHI</td>\n",
       "      <td>&amp;=babble .</td>\n",
       "      <td>['.']</td>\n",
       "      <td>['none']</td>\n",
       "      <td>512973.0</td>\n",
       "      <td>513639.0</td>\n",
       "      <td>12</td>\n",
       "      <td>Brent</td>\n",
       "      <td>/home/mitja/data/CHILDES/Brent/c1/000917.cha</td>\n",
       "      <td>...</td>\n",
       "      <td>517483.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>YY</td>\n",
       "      <td>361.0</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   utterance_id speaker_code transcript_raw tokens       pos  start_time  \\\n",
       "0             9          CHI   &=vocalize .  ['.']  ['none']     15320.0   \n",
       "1           157          CHI   &=vocalize .  ['.']  ['none']    367633.0   \n",
       "2           160          CHI   &=vocalize .  ['.']  ['none']    372007.0   \n",
       "3           162          CHI   &=vocalize .  ['.']  ['none']    381680.0   \n",
       "4           194          CHI     &=babble .  ['.']  ['none']    512973.0   \n",
       "\n",
       "   end_time  age corpus                               transcript_file  ...  \\\n",
       "0   16139.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "1  368084.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "2  372211.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "3  381906.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "4  513639.0   12  Brent  /home/mitja/data/CHILDES/Brent/c1/000917.cha  ...   \n",
       "\n",
       "  follow_up_start_time follow_up_is_speech_related  follow_up_is_intelligible  \\\n",
       "0              19069.0                         1.0                          0   \n",
       "1             370041.0                         1.0                          0   \n",
       "2             381680.0                         1.0                          0   \n",
       "3             386103.0                         1.0                          0   \n",
       "4             517483.0                         1.0                          0   \n",
       "\n",
       "   follow_up_is_contingent  follow_up_speech_act  response_latency  \\\n",
       "0                        0                    YY            -252.0   \n",
       "1                        0                    YY             528.0   \n",
       "2                        0                    YY            6830.0   \n",
       "3                        0                    YY            1965.0   \n",
       "4                        0                    YY             361.0   \n",
       "\n",
       "  response_latency_follow_up has_response  pos_feedback  \\\n",
       "0                     2930.0            1             1   \n",
       "1                     1957.0            1             1   \n",
       "2                     9469.0            0             0   \n",
       "3                     4197.0            0             0   \n",
       "4                     3844.0            1             1   \n",
       "\n",
       "  response_is_clarification_request  \n",
       "0                                 0  \n",
       "1                                 0  \n",
       "2                                 0  \n",
       "3                                 0  \n",
       "4                                 0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "conversations = pd.read_csv(\"results/contingency/conversations.csv\")\n",
    "\n",
    "# convert True/False to 0/1:\n",
    "conversations.replace({False: 0, True: 1}, inplace=True)\n",
    "\n",
    "conversations.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "child_name\n",
       "Braunwald_Laura                7529\n",
       "Brent_Alexander                 133\n",
       "Brent_Allen                       3\n",
       "Brent_Brooklyn                    8\n",
       "Brent_Dillon                    532\n",
       "Brent_Henry                      92\n",
       "Brent_Jacob_Abernathy             4\n",
       "Brent_Jaylen                     35\n",
       "Brent_Maggie                    114\n",
       "Brent_Miranda                   105\n",
       "Brent_Morgan                    414\n",
       "Brent_Tabitha                   187\n",
       "Brent_Tabitha_Sims                3\n",
       "Brent_Timothy                   306\n",
       "Brent_Tyrese                      6\n",
       "Brent_Vas                        11\n",
       "Brent_Vas_Coleman                87\n",
       "Brent_Xavier                      9\n",
       "MPI-EVA-Manchester_Eleanor    40925\n",
       "MPI-EVA-Manchester_Fraser     90496\n",
       "Thomas_Brian                    302\n",
       "Thomas_Thomas                 90240\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some children have very few data points:\n",
    "counts = conversations.groupby(\"child_name\").size()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Exclude children with less than 100 datapoints:\n",
    "# child_names_enough_data = [name for name, count in counts.items() if count > 100]\n",
    "# print(len(conversations))\n",
    "# conversations = conversations[conversations.child_name.isin(child_names_enough_data)]\n",
    "# print(len(conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize age\n",
    "min_age, max_age = conversations[\"age\"].min(), conversations[\"age\"].max()\n",
    "conversations[\"age\"] = (conversations[\"age\"] - min_age) / (max_age - min_age) * (1 - 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality of communicative feedback/ Caregiver contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: has_response ~ is_intelligible * age_normalized + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "173345.9 173397.7 -86668.0 173335.9   231536 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-4.4872  0.3109  0.3410  0.3895  0.9238 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 0.2714   0.5209  \n",
      "Number of obs: 231541, groups:  child_name, 22\n",
      "\n",
      "Fixed effects:\n",
      "                               Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                     0.78918    0.10351   7.624 2.46e-14 ***\n",
      "is_intelligible                 0.79457    0.04085  19.449  < 2e-16 ***\n",
      "age_normalized                  0.66146    0.06743   9.810  < 2e-16 ***\n",
      "is_intelligible:age_normalized  0.44585    0.07488   5.954 2.62e-09 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl ag_nrm\n",
      "is_intllgbl -0.048              \n",
      "age_normlzd -0.047  0.724       \n",
      "is_ntllgb:_  0.038 -0.922 -0.802\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('has_response ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: \n",
      "response_is_clarification_request ~ is_intelligible * age_normalized +  \n",
      "    (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      " 15518.4  15570.2  -7754.2  15508.4   231536 \n",
      "\n",
      "Scaled residuals: \n",
      "   Min     1Q Median     3Q    Max \n",
      "-0.283 -0.075 -0.072 -0.031 36.393 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 1.056    1.028   \n",
      "Number of obs: 231541, groups:  child_name, 22\n",
      "\n",
      "Fixed effects:\n",
      "                               Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                     -3.7426     0.2366 -15.819  < 2e-16 ***\n",
      "is_intelligible                 -2.6123     0.1223 -21.367  < 2e-16 ***\n",
      "age_normalized                  -2.0319     0.2035  -9.987  < 2e-16 ***\n",
      "is_intelligible:age_normalized   1.6127     0.2326   6.934 4.09e-12 ***\n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl ag_nrm\n",
      "is_intllgbl  0.020              \n",
      "age_normlzd -0.090  0.412       \n",
      "is_ntllgb:_ -0.014 -0.893 -0.546\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('response_is_clarification_request ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (Positive Feedback = No pause, no clarification request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: pos_feedback ~ is_intelligible * age_normalized + (1 | child_name)\n",
      "   Data: conversations\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "177320.8 177372.6 -88655.4 177310.8   231536 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-4.2027  0.3113  0.3407  0.4003  0.9944 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 0.3022   0.5497  \n",
      "Number of obs: 231541, groups:  child_name, 22\n",
      "\n",
      "Fixed effects:\n",
      "                               Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                     0.62859    0.09246   6.798 1.06e-11 ***\n",
      "is_intelligible                 1.00836    0.04093  24.636  < 2e-16 ***\n",
      "age_normalized                  0.89248    0.06463  13.809  < 2e-16 ***\n",
      "is_intelligible:age_normalized  0.19024    0.07467   2.548   0.0108 *  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) is_ntl ag_nrm\n",
      "is_intllgbl -0.065              \n",
      "age_normlzd -0.077  0.724       \n",
      "is_ntllgb:_  0.062 -0.925 -0.800\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "m_caregiver_contingency<-glmer('pos_feedback ~ is_intelligible * age + (1 | child_name)', data=conversations, family=binomial)\n",
    "print(summary(m_caregiver_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of communicative feedback\n",
    "### Positive Feedback: Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: follow_up_is_intelligible ~ has_response * age + (1 | child_name)\n",
      "   Data: conversations_child_intelligible\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      "125671.7 125722.9 -62830.8 125661.7   210249 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-4.4316  0.2664  0.2895  0.3307  1.3472 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 1.181    1.087   \n",
      "Number of obs: 210254, groups:  child_name, 21\n",
      "\n",
      "Fixed effects:\n",
      "                 Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)       1.54459    0.12530  12.327  < 2e-16 ***\n",
      "has_response      0.32964    0.04483   7.354 1.93e-13 ***\n",
      "age               1.09402    0.07180  15.237  < 2e-16 ***\n",
      "has_response:age -0.09705    0.07939  -1.222    0.222    \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) hs_rsp age   \n",
      "has_respons -0.125              \n",
      "age         -0.136  0.675       \n",
      "has_rspns:g  0.132 -0.922 -0.745\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "conversations_child_intelligible = subset(conversations, is_intelligible==1)\n",
    "# TODO: only intelligible ones?\n",
    "\n",
    "m_child_contingency<-glmer('follow_up_is_intelligible ~ has_response * age + (1 | child_name)', data=conversations_child_intelligible, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Negative Feedback: Clarification requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized linear mixed model fit by maximum likelihood (Laplace\n",
      "  Approximation) [glmerMod]\n",
      " Family: binomial  ( logit )\n",
      "Formula: follow_up_is_intelligible ~ response_is_clarification_request *  \n",
      "    age + (1 | child_name)\n",
      "   Data: conversations_unintelligible\n",
      "\n",
      "     AIC      BIC   logLik deviance df.resid \n",
      " 34111.7  34153.1 -17050.9  34101.7    29291 \n",
      "\n",
      "Scaled residuals: \n",
      "    Min      1Q  Median      3Q     Max \n",
      "-3.3318 -1.1835  0.6085  0.6968 11.1542 \n",
      "\n",
      "Random effects:\n",
      " Groups     Name        Variance Std.Dev.\n",
      " child_name (Intercept) 5.405    2.325   \n",
      "Number of obs: 29296, groups:  child_name, 17\n",
      "\n",
      "Fixed effects:\n",
      "                                      Estimate Std. Error z value Pr(>|z|)    \n",
      "(Intercept)                           -1.64034    0.47541  -3.450  0.00056 ***\n",
      "response_is_clarification_request     -0.59214    0.23912  -2.476  0.01328 *  \n",
      "age                                    1.54679    0.08572  18.045  < 2e-16 ***\n",
      "response_is_clarification_request:age  1.23226    0.51790   2.379  0.01734 *  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Correlation of Fixed Effects:\n",
      "            (Intr) rsp___ age   \n",
      "rspns_s_cl_  0.040              \n",
      "age         -0.017  0.107       \n",
      "rspns_s_c_: -0.042 -0.929 -0.097\n"
     ]
    }
   ],
   "source": [
    "%%R -i conversations\n",
    "library(lme4)\n",
    "\n",
    "conversations_unintelligible = subset(conversations, is_intelligible == 0)\n",
    "\n",
    "\n",
    "m_child_contingency<-glmer('follow_up_is_intelligible ~ response_is_clarification_request * age + (1 | child_name)', data=conversations_unintelligible, family=binomial)\n",
    "print(summary(m_child_contingency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}